{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-Az0qKpSjNR",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import ast  # To safely parse the 'nutrition' strings into lists\n",
        "\n",
        "raw_recipes = pd.read_csv(\"RAW_recipes.csv\")\n",
        "columns_to_keep = [\"name\", \"id\", \"minutes\", \"nutrition\"]\n",
        "raw_recipes = raw_recipes[columns_to_keep]\n",
        "raw_recipes[\"calories\"] = raw_recipes[\"nutrition\"].apply(lambda x: ast.literal_eval(x)[0] if pd.notna(x) else None)\n",
        "raw_recipes = raw_recipes.drop(columns=[\"nutrition\"])\n",
        "\n",
        "print(\"\\nStatistics for 'minutes' before filtering:\")\n",
        "print(raw_recipes[\"minutes\"].describe())\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(raw_recipes[\"minutes\"], bins=50, color=\"skyblue\", edgecolor=\"black\")\n",
        "plt.title(\"Distribution of Cooking Times (Minutes)\")\n",
        "plt.xlabel(\"Minutes\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out rows where \"minutes\" > 300\n",
        "initial_count = len(raw_recipes)\n",
        "raw_recipes_filtered_mins = raw_recipes[raw_recipes[\"minutes\"] <= 300]\n",
        "raw_recipes_filtered_mins = raw_recipes_filtered_mins[raw_recipes_filtered_mins[\"minutes\"] > 0]\n",
        "final_count = len(raw_recipes_filtered_mins)\n",
        "rows_dropped = initial_count - final_count\n",
        "print(f\"Number of rows dropped: {rows_dropped}\")\n",
        "\n",
        "print(\"\\nStatistics for 'minutes' after filtering:\")\n",
        "print(raw_recipes_filtered_mins[\"minutes\"].describe())\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(raw_recipes_filtered_mins[\"minutes\"], bins=50, color=\"skyblue\", edgecolor=\"black\")\n",
        "plt.title(\"Distribution of Cooking Times (Minutes)\")\n",
        "plt.xlabel(\"Minutes\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "# Find the median of the \"minutes\" column\n",
        "median_minutes = raw_recipes_filtered_mins[\"minutes\"].median()\n",
        "\n",
        "# Filter recipes with \"minutes\" less than or equal to the median\n",
        "quick_recipes = raw_recipes_filtered_mins[raw_recipes_filtered_mins[\"minutes\"] <= median_minutes]\n",
        "print(f\"\\nMedian cooking time (minutes): {median_minutes}\")"
      ],
      "metadata": {
        "id": "cz3FI4eaRn7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the distribution of the \"minutes\" variable\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(quick_recipes[\"minutes\"], bins=50, color=\"skyblue\", edgecolor=\"black\")\n",
        "plt.title(\"Distribution of Cooking Times Below Median (Minutes)\")\n",
        "plt.xlabel(\"Minutes\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gxLF7LpRR8P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_interactions = pd.read_csv(\"RAW_interactions.csv\")\n",
        "columns_to_keep = [\"user_id\", \"recipe_id\", \"rating\"]\n",
        "raw_interactions = raw_interactions[columns_to_keep]\n",
        "\n",
        "# Filter out interactions where \"recipe_id\" is in \"quick_recipes\"\n",
        "quick_recipe_ids = set(quick_recipes[\"id\"])  # faster lookup\n",
        "quick_interactions = raw_interactions[raw_interactions[\"recipe_id\"].isin(quick_recipe_ids)]\n",
        "\n",
        "print(quick_interactions.head())\n",
        "print(f\"\\nNumber of interactions in raw_interactions: {len(raw_interactions)}\")\n",
        "print(f\"\\nNumber of interactions in quick_interactions: {len(quick_interactions)}\")"
      ],
      "metadata": {
        "id": "TJS5ARiYSAwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nStatistics for 'calories' before filtering:\")\n",
        "print(raw_recipes[\"calories\"].describe())\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(raw_recipes[\"calories\"], bins=50, color=\"skyblue\", edgecolor=\"black\")\n",
        "plt.title(\"Distribution of Calorie Counts (kCal)\")\n",
        "plt.xlabel(\"Calories\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yCu-3y2LSEzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out rows where 10 < \"calories\" < 2000\n",
        "initial_count = len(raw_recipes)\n",
        "raw_recipes_filtered_cals = raw_recipes[raw_recipes[\"calories\"] <= 2000]\n",
        "raw_recipes_filtered_cals = raw_recipes_filtered_cals[raw_recipes_filtered_cals[\"calories\"] > 10]\n",
        "final_count = len(raw_recipes_filtered_cals)\n",
        "rows_dropped = initial_count - final_count\n",
        "print(f\"Number of rows dropped: {rows_dropped}\")\n",
        "\n",
        "print(\"\\nStatistics for 'calories' after filtering:\")\n",
        "print(raw_recipes_filtered_cals[\"calories\"].describe())\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(raw_recipes_filtered_cals[\"calories\"], bins=50, color=\"skyblue\", edgecolor=\"black\")\n",
        "plt.title(\"Distribution of Calorie Counts (kCal)\")\n",
        "plt.xlabel(\"Calories\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "# Find the median of the \"calories\" column\n",
        "median_calories = raw_recipes_filtered_cals[\"calories\"].median()\n",
        "\n",
        "# Filter recipes with \"calories\" less than or equal to the median\n",
        "low_cal_recipes = raw_recipes_filtered_cals[raw_recipes_filtered_cals[\"calories\"] <= median_calories]\n",
        "print(f\"\\nMedian calorie count (kCal): {median_calories}\")"
      ],
      "metadata": {
        "id": "p1_Sn-p8SI08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the distribution of the \"calories\" variable\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(low_cal_recipes[\"calories\"], bins=50, color=\"skyblue\", edgecolor=\"black\")\n",
        "plt.title(\"Distribution of Calorie Counts Below Median (kCal)\")\n",
        "plt.xlabel(\"Calories\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VU5UUeCoSMRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter out interactions where \"recipe_id\" is in \"quick_recipes\"\n",
        "low_cal_recipe_ids = set(low_cal_recipes[\"id\"])  # faster lookup\n",
        "low_cal_interactions = raw_interactions[raw_interactions[\"recipe_id\"].isin(low_cal_recipe_ids)]\n",
        "\n",
        "print(low_cal_interactions.head())\n",
        "print(f\"\\nNumber of interactions in raw_interactions: {len(raw_interactions)}\")\n",
        "print(f\"\\nNumber of interactions in low_cal_interactions: {len(low_cal_interactions)}\")"
      ],
      "metadata": {
        "id": "Sh_8ICPRSQ7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quick_recipes.to_csv(\"quick_recipes.csv\", index=False)\n",
        "quick_interactions.to_csv(\"quick_interactions.csv\", index=False)\n",
        "low_cal_recipes.to_csv(\"low_cal_recipes.csv\", index=False)\n",
        "low_cal_interactions.to_csv(\"low_cal_interactions.csv\", index=False)"
      ],
      "metadata": {
        "id": "oJMWAHgRSVGz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Load the low-calorie interactions dataset\n",
        "low_cal_interactions = pd.read_csv(\"low_cal_interactions.csv\")\n",
        "\n",
        "# Data splitting: training (80%), validation (10%), testing (10%)\n",
        "random_seed = 42\n",
        "train_data, temp_data = train_test_split(\n",
        "    low_cal_interactions, test_size=0.2, random_state=random_seed\n",
        ")\n",
        "validation_data, test_data = train_test_split(\n",
        "    temp_data, test_size=0.5, random_state=random_seed\n",
        ")\n",
        "\n",
        "# Print dataset sizes\n",
        "print(f\"Training set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(validation_data)}\")\n",
        "print(f\"Testing set size: {len(test_data)}\")\n",
        "\n",
        "# Save splits to CSV (optional)\n",
        "train_data.to_csv(\"low_cal_train.csv\", index=False)\n",
        "validation_data.to_csv(\"low_cal_validation.csv\", index=False)\n",
        "test_data.to_csv(\"low_cal_test.csv\", index=False)\n",
        "\n",
        "# Check train-test overlap\n",
        "train_users = set(train_data[\"user_id\"])\n",
        "train_recipes = set(train_data[\"recipe_id\"])\n",
        "\n",
        "valid_users_covered = all(user in train_users for user in validation_data[\"user_id\"])\n",
        "valid_recipes_covered = all(recipe in train_recipes for recipe in validation_data[\"recipe_id\"])\n",
        "test_users_covered = all(user in train_users for user in test_data[\"user_id\"])\n",
        "test_recipes_covered = all(recipe in train_recipes for recipe in test_data[\"recipe_id\"])\n",
        "\n",
        "print(f\"Validation users covered: {valid_users_covered}\")\n",
        "print(f\"Validation recipes covered: {valid_recipes_covered}\")\n",
        "print(f\"Test users covered: {test_users_covered}\")\n",
        "print(f\"Test recipes covered: {test_recipes_covered}\")\n",
        "\n",
        "# Bias-Only Model\n",
        "\n",
        "# Step 1: Compute Global Bias\n",
        "global_bias = train_data[\"rating\"].mean()\n",
        "print(f\"Global Bias (mean rating): {global_bias}\")\n",
        "\n",
        "# Step 2: Compute User Biases\n",
        "user_bias = (\n",
        "    train_data.groupby(\"user_id\")[\"rating\"]\n",
        "    .mean()\n",
        "    .subtract(global_bias)\n",
        "    .to_dict()\n",
        ")\n",
        "\n",
        "# Step 3: Compute Recipe Biases\n",
        "recipe_bias = (\n",
        "    train_data.groupby(\"recipe_id\")[\"rating\"]\n",
        "    .mean()\n",
        "    .subtract(global_bias)\n",
        "    .to_dict()\n",
        ")\n",
        "\n",
        "# Step 4: Prediction Function\n",
        "def predict(user_id, recipe_id):\n",
        "    \"\"\"\n",
        "    Predict the rating for a given user and recipe based on biases.\n",
        "    \"\"\"\n",
        "    user_b = user_bias.get(user_id, 0)  # Default to 0 if user not in training\n",
        "    recipe_b = recipe_bias.get(recipe_id, 0)  # Default to 0 if recipe not in training\n",
        "    return global_bias + user_b + recipe_b\n",
        "\n",
        "# Step 5: Evaluate Model with MSE\n",
        "def evaluate(data, name=\"Dataset\"):\n",
        "    \"\"\"\n",
        "    Evaluate the model on a dataset by calculating MSE.\n",
        "    \"\"\"\n",
        "    y_true = data[\"rating\"]\n",
        "    y_pred = data.apply(lambda row: predict(row[\"user_id\"], row[\"recipe_id\"]), axis=1)\n",
        "    mse = np.mean((y_true - y_pred) ** 2)\n",
        "    print(f\"MSE on {name}: {mse}\")\n",
        "    return mse\n",
        "\n",
        "# Evaluate on Training, Validation, and Testing Sets\n",
        "evaluate(train_data, \"Training Set\")\n",
        "evaluate(validation_data, \"Validation Set\")\n",
        "evaluate(test_data, \"Testing Set\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMVkIjRLn2St",
        "outputId": "e5986ab5-d128-42f1-d656-90fd13d404a8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 439821\n",
            "Validation set size: 54978\n",
            "Testing set size: 54978\n",
            "Validation users covered: False\n",
            "Validation recipes covered: False\n",
            "Test users covered: False\n",
            "Test recipes covered: False\n",
            "Global Bias (mean rating): 4.420857576150297\n",
            "MSE on Training Set: 0.6844740441212623\n",
            "MSE on Validation Set: 1.7480310314739416\n",
            "MSE on Testing Set: 1.772939838651607\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.772939838651607"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load quick recipes and interactions\n",
        "quick_recipes = pd.read_csv(\"quick_recipes.csv\")\n",
        "quick_interactions = pd.read_csv(\"quick_interactions.csv\")\n",
        "\n",
        "# Split the data into train (80%), validation (10%), and test (10%)\n",
        "train_data, temp_data = train_test_split(quick_interactions, test_size=0.2, random_state=42)\n",
        "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
        "\n",
        "print(f\"Training set size: {len(train_data)}\")\n",
        "print(f\"Validation set size: {len(val_data)}\")\n",
        "print(f\"Test set size: {len(test_data)}\")\n",
        "\n",
        "# Global mean (mu)\n",
        "global_bias = train_data[\"rating\"].mean()\n",
        "\n",
        "# User biases\n",
        "lambda_reg = 10  # Regularization strength\n",
        "user_bias = (\n",
        "    train_data.groupby(\"user_id\")[\"rating\"]\n",
        "    .apply(lambda x: (x - global_bias).sum() / (len(x) + lambda_reg))\n",
        "    .to_dict()\n",
        ")\n",
        "\n",
        "# Recipe biases\n",
        "recipe_bias = (\n",
        "    train_data.groupby(\"recipe_id\")[\"rating\"]\n",
        "    .apply(lambda x: (x - global_bias - user_bias.get(x.name, 0)).sum() / (len(x) + lambda_reg))\n",
        "    .to_dict()\n",
        ")\n",
        "\n",
        "# Prediction function\n",
        "def predict(user_id, recipe_id):\n",
        "    \"\"\"Predict rating for a given user and recipe.\"\"\"\n",
        "    user_b = user_bias.get(user_id, 0)\n",
        "    recipe_b = recipe_bias.get(recipe_id, 0)\n",
        "    return global_bias + user_b + recipe_b\n",
        "\n",
        "# Evaluate model\n",
        "def evaluate(data, label=\"Set\"):\n",
        "    \"\"\"Evaluate model performance on a given dataset.\"\"\"\n",
        "    predictions = data.apply(lambda row: predict(row[\"user_id\"], row[\"recipe_id\"]), axis=1)\n",
        "    mse = mean_squared_error(data[\"rating\"], predictions)\n",
        "    print(f\"{label} MSE: {mse}\")\n",
        "    return mse\n",
        "\n",
        "# Evaluate on all splits\n",
        "print(\"\\nEvaluating the model:\")\n",
        "train_mse = evaluate(train_data, \"Train\")\n",
        "val_mse = evaluate(val_data, \"Validation\")\n",
        "test_mse = evaluate(test_data, \"Test\")\n",
        "\n",
        "# Output the model's predictions on test data (optional)\n",
        "test_data[\"predicted_rating\"] = test_data.apply(lambda row: predict(row[\"user_id\"], row[\"recipe_id\"]), axis=1)\n",
        "test_data.to_csv(\"quick_recipes_test_predictions.csv\", index=False)\n",
        "\n",
        "print(\"\\nPredictions saved to 'quick_recipes_test_predictions.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHUVDBCN2ckV",
        "outputId": "06fde8cf-b6c7-4623-93c9-b95704b9432a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 428936\n",
            "Validation set size: 53617\n",
            "Test set size: 53617\n",
            "\n",
            "Evaluating the model:\n",
            "Train MSE: 1.093801375648195\n",
            "Validation MSE: 1.3541831216510385\n",
            "Test MSE: 1.3589729169254396\n",
            "\n",
            "Predictions saved to 'quick_recipes_test_predictions.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Step 1: Preprocessing the Data\n",
        "# Load raw recipes and interactions\n",
        "raw_recipes = pd.read_csv(\"RAW_recipes.csv\")\n",
        "raw_interactions = pd.read_csv(\"RAW_interactions.csv\")\n",
        "\n",
        "# Keep relevant columns\n",
        "raw_recipes = raw_recipes[[\"name\", \"id\", \"minutes\", \"nutrition\"]]\n",
        "raw_recipes[\"calories\"] = raw_recipes[\"nutrition\"].apply(lambda x: ast.literal_eval(x)[0] if pd.notna(x) else None)\n",
        "raw_recipes = raw_recipes.drop(columns=[\"nutrition\"])\n",
        "\n",
        "raw_interactions = raw_interactions[[\"user_id\", \"recipe_id\", \"rating\"]]\n",
        "\n",
        "# Filter recipes based on calories and minutes\n",
        "raw_recipes = raw_recipes[(raw_recipes[\"calories\"] <= 2000) & (raw_recipes[\"calories\"] > 10)]\n",
        "raw_recipes = raw_recipes[(raw_recipes[\"minutes\"] <= 300) & (raw_recipes[\"minutes\"] > 0)]\n",
        "\n",
        "# Filter interactions to include only valid recipe_ids\n",
        "all_recipe_ids = set(raw_recipes[\"id\"])\n",
        "all_interactions = raw_interactions[raw_interactions[\"recipe_id\"].isin(all_recipe_ids)]\n",
        "\n",
        "# Step 2: Train/Test Split\n",
        "# Use an 80-10-10 split for training, validation, and testing\n",
        "np.random.seed(42)  # For reproducibility\n",
        "shuffled_indices = np.random.permutation(len(all_interactions))\n",
        "train_end = int(0.8 * len(shuffled_indices))\n",
        "valid_end = int(0.9 * len(shuffled_indices))\n",
        "\n",
        "train_indices = shuffled_indices[:train_end]\n",
        "valid_indices = shuffled_indices[train_end:valid_end]\n",
        "test_indices = shuffled_indices[valid_end:]\n",
        "\n",
        "train_data = all_interactions.iloc[train_indices]\n",
        "valid_data = all_interactions.iloc[valid_indices]\n",
        "test_data = all_interactions.iloc[test_indices]\n",
        "\n",
        "# Step 3: Bias-Only Model\n",
        "# Calculate global bias, user biases, and item biases\n",
        "global_bias = train_data[\"rating\"].mean()\n",
        "\n",
        "# Calculate user and item biases\n",
        "user_bias = train_data.groupby(\"user_id\")[\"rating\"].mean() - global_bias\n",
        "item_bias = train_data.groupby(\"recipe_id\")[\"rating\"].mean() - global_bias\n",
        "\n",
        "# Fill missing biases with 0 for new users/items in validation or test\n",
        "user_bias = user_bias.to_dict()\n",
        "item_bias = item_bias.to_dict()\n",
        "\n",
        "def predict(user_id, recipe_id):\n",
        "    \"\"\"\n",
        "    Predict rating based on bias model: global_bias + user_bias + item_bias\n",
        "    \"\"\"\n",
        "    user_b = user_bias.get(user_id, 0)\n",
        "    item_b = item_bias.get(recipe_id, 0)\n",
        "    return global_bias + user_b + item_b\n",
        "\n",
        "# Step 4: Evaluation\n",
        "def evaluate(data):\n",
        "    \"\"\"\n",
        "    Evaluate the model using Mean Squared Error (MSE).\n",
        "    \"\"\"\n",
        "    y_true = data[\"rating\"]\n",
        "    y_pred = data.apply(lambda row: predict(row[\"user_id\"], row[\"recipe_id\"]), axis=1)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    return mse\n",
        "\n",
        "# Calculate MSE for train, validation, and test sets\n",
        "train_mse = evaluate(train_data)\n",
        "valid_mse = evaluate(valid_data)\n",
        "test_mse = evaluate(test_data)\n",
        "\n",
        "print(f\"Train MSE: {train_mse:.4f}\")\n",
        "print(f\"Validation MSE: {valid_mse:.4f}\")\n",
        "print(f\"Test MSE: {test_mse:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GO8PetrapsSr",
        "outputId": "42907d19-c9d7-4f2b-efb3-a9c567c9688b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train MSE: 0.7199\n",
            "Validation MSE: 1.7852\n",
            "Test MSE: 1.7891\n"
          ]
        }
      ]
    }
  ]
}